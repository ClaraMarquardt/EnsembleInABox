function_name,function_title,function_desc,function_return,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,
datasets,,,,,,,,,,,,,,,,,,
ExpLearning.Default,[Dataset] Default values for all parameters associated with the ExpLearning Package. ,.,.,,,,,,,,,,,,,,,
ExpLearning.Parameter,[Dataset] Overview of all parameters associated with the ExpLearning Package.,.,.,,,,,,,,,,,,,,,
ExpLearning.MLParameter,"[Dataset] Overview of all ml parameters, i.e. tuning parameters, associated with the learners in the ExpLearning Package.",.,.,,,,,,,,,,,,,,,
test_df,[Dataset] Simple data.table useful for testing purposes.,.,.,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,
data preparation,,,,,,,,,,,,,,,,,,
prepare_data,Prepare a data.table containing the raw data for further processing with the ExpLearning Package and generate a configuration dictionary.,.,List with the modified data.table ('df') and the configuration dictionary ('dict').,,,,,,,,,,,,,,,
complete_data,Convert a data.table into a data.table containing only complete observations (and potentially featuring missigness indicators).,.,Complete data.table ('df') alongside a list of variables affected by missingness ('miss_var'). ,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,
fold construction,,,,,,,,,,,,,,,,,,
blocked_stratification ,Split a data.table into stratified cluster-level subsets. ,.,Vector of subset IDs (to be merged into original data.table). ,,,,,,,,,,,,,,,
gen_fold,Generate cluster-level CV folds.,Holdout set construction optionally targeting (i) the cluster count (ii) the sample size or (iii) stratification.,Modified data.table containing fold IDs for each observation.,,,,,,,,,,,,,,,
gen_holdout,Generate a cluster-level holdout set.,Holdout set construction optionally targeting (i) the cluster count (ii) the sample size or (iii) stratification.,"Modified data.table containing a holdout set identifier (TRUE, FALSE)  for each observation.",,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,
miscellaneous helper functions,,,,,,,,,,,,,,,,,,
loss,"Calculate specified regression, classification loss (or gain) given a vector of predictions and a vector of labels. ",.,Loss. ,,,,,,,,,,,,,,,
expand_split_grid,Convert a list of tuning parameters into a list of data.tables each containing one tuning parameter combination. ,.,Formatted parameter tuning grid.,,,,,,,,,,,,,,,
extract_param,Convert tuning parameters returned as part of the results into a list of parameters which can be passed to the next round as a custom_param argument. ,.,Formatted list of tuning parameters. ,,,,,,,,,,,,,,,
load_dep,Load all dependencies. ,.,.,,,,,,,,,,,,,,,
model_predict_function_template,Ensemble prediction function template. ,.,.,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,
model construction and prediction,,,,,,,,,,,,,,,,,,
holdout_predict,Construct an ensemble model using a training subset of the data and generate out of sample predictions based on this model. ,.,A list with out of sample predictions as well as hyperparameters and ensemble weights. ,,,,,,,,,,,,,,,
holdout_opt_predict,Construct an ensemble model using a training subset of the data (following a computationally optimised procedure) and generate out of sample predictions based on this model. ,.,A list with out of sample predictions as well as hyperparameters and ensemble weights. ,,,,,,,,,,,,,,,
kfold_predict,Construct an ensemble model using the entire data set and generate CV-based (out of sample predictions) based on this model. ,.,A list with CV-based (out of sample predictions) as well as hyperparameters and ensemble weights. ,,,,,,,,,,,,,,,
kfold_opt_predict,Construct an ensemble model using the entire data set (following a computationally optimised procedure)  and generate CV-based (out of sample predictions) based on this model. ,.,A list with cv-based (out of sample predictions) as well as hyperparameters and ensemble weights. ,,,,,,,,,,,,,,,
ensemble_predict,Generate an in-sample fitted ensembled based on in-sample tuned out of sample predictions. ,.,A list of ensemble weights and tuning parameters selected for each of the individual learners. ,,,,,,,,,,,,,,,
oos_predict,Generate out of sample predictions based on a set of given ensemble weights and a list of individual leaners each of which is fit and tuned on the entire training data. ,.,A list of out of sample predictions generated by (a) the ensemble  and (b) the individual learners along with ,,,,,,,,,,,,,,,
tuned_predict,Generate out of sample predictions based on in-sample cross-validation. ,.,A list of out of sample predictions along with the optimal parameters selected. ,,,,,,,,,,,,,,,
tuning,Implement k-fold cross-validation on a subset of the data to tune the parameters of a given model (according to a specified tuning strategy). ,.,A list of out of sample predictions along with the optimal parameters selected. ,,,,,,,,,,,,,,,
wald_ensemble,"Perform a series of Wald tests to test the significance of the group_var and control_var in a regression of the assignment var on the  group_var, control_var and unbalanced_control_var.",.,A list of p-values for each of the wald tests.,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,
result analysis,,,,,,,,,,,,,,,,,,
holdout_analysis,Analyse the predictive performance of the out of sample predictions derived from the model. ,.,"List of losses, a p-value and a data.table with the original data alongside the final, out of sample predictions for the ensemble and each of the individual learners. ",,,,,,,,,,,,,,,
kfold_analysis,Analyse the predictive performance of the CV-based (out of sample) predictions derived from the model. ,.,"List of losses, a p-value and a data.table with the original data alongside the final, CV-based (out of sample predictions) for the ensemble and each of the individual learners. ",,,,,,,,,,,,,,,
perm_analysis,Generate a permutation testing plot (plot of the permuted losses and the model loss). ,.,Permutation testing plot. ,,,,,,,,,,,,,,,
perm,Perform cluster-level permutations of a specified variable in a given data.table. ,.,Modified data.table with permuted variable. ,,,,,,,,,,,,,,,
perm_testing,Derive a permutation testing based p-value for a given model. ,.,"List with p-values, permuted losses and model losses. ",,,,,,,,,,,,,,,
agg_tuning_plot,Generate and save a plot of tuning parameters and the resulting losses. ,Aggregate rather than parameter-specific tuning plot. ,. ,,,,,,,,,,,,,,,
format_output,Format the model output. ,.,A list with the formatted model output. ,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,
interfaces,,,,,,,,,,,,,,,,,,
effect_on_group,Construct an ensemble model to test the predictability of an outcome variable based on one or more predictors [Interface].,.,"List with the (final - CV or holdout) loss ['main_loss'], the mean (final - CV or holdout) permuted loss ['perm_loss'], the individual permutation losses ['perm_loss_raw'], the p-value ['pval'], the runtime in seconds ['run_time'], the selected tuning parameters for each of the learners ['inner_param' and 'outer_param'], the out of sample auc of the final model ['main_loss_auc'] as well as the out of sample losses for each of the individual learners ['indiv_loss']. ",,,,,,,,,,,,,,,
holdout_outcome_predict,Construct an ensemble model using a holdout set and generate out of sample predictions based on this model [Interface]. ,.,A list with out of sample predictions as well as hyperparameters and ensemble weights. ,,,,,,,,,,,,,,,
kfold_outcome_predict,Construct an ensemble model using the entire data and generate CV-based (out of sample) predictions based on this model [Interface]. ,,A list with out of sample predictions as well as hyperparameters and ensemble weights. ,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,
algorithm,,,,,,,,,,,,,,,,,,
alg,Combine an algorithm with a list of tuning parameters. ,.,List with the algorithm ['algorithm'] and the parameters ['parameter'].,,,,,,,,,,,,,,,
olsalg,Fit a linear regression to a subset of the data and return predictions for (i) a (different) subset of the data and (ii) the original data.,Linear regression constructed using: lm (...) [base R]. Observation weights (weight_var) are handled internally (method: minimise weighted loss function) in the training stage (not taken into account at the prediction stage). ,Vector of predictions (predicted value of Y) ['pred' 'pred_is'] and the fitted learner ['learner'].,,,,,,,,,,,,,,,
logitalg,Fit a logistic regression to a subset of the data and return predictions for (i) a (different) subset of the data and (ii) the original data.,"Logistic regression constructed using glm (..., family='binomial')  [base R].  Observation weights (weight_var) are handled internally (method: minimise weighted loss function) in the training stage (not taken into account at the prediction stage). ",Vector of predictions (predicted probability of Y==1) ['pred' 'pred_is'] and the fitted learner ['learner'].,,,,,,,,,,,,,,,
treealg,Fit a tree (classification regression) to a subset of the data and return predictions for (i) a (different) subset of the data and (ii) the original data.,"Tree constructed using rpart(..., method='anova') [rpart]. Observation weights (weight_var) are handled internally (method: Observation with heigher weights are selected with higher probability in the bootstrap samples used to construct the individual trees) in the training stage (not taken into account at the prediction stage). ",Vector of predictions (predicted value of Y  OR  predicted probability of Y==1) ['pred' 'pred_is'] and the fitted learner ['learner'].,,,,,,,,,,,,,,,
rfalg,Fit a random forest model (classification regression) to a subset of the data and return predictions for (i) a (different) subset of the data and (ii) the original data.,Random forest constructed using ranger [ranger]. Observation weights (weight_var) are handled internally (method: Observation with heigher weights are selected with higher probability in the bootstrap samples used to construct the individual trees) in the training stage (not taken into account at the prediction stage). ,Vector of predictions (predicted value of Y  OR  predicted probability of Y==1) ['pred' 'pred_is'] and the fitted learner ['learner'].,,,,,,,,,,,,,,,
elnetalg,Fit an elastic net regression (classification - logit regression - ols) to a subset of the data and return predictions for (i) a (different) subset of the data and (ii) the original data.,"Elastic net constructed using glmnet(..., method='gaussian' 'binomial') [glmnet]. Observation weights (weight_var) are handled internally (method: minimise weighted loss function) in the training stage (not taken into account at the prediction stage). ",Vector of predictions (predicted value of Y OR predicted probability of Y==1) ['pred' 'pred_is'] and the fitted learner ['learner'].,,,,,,,,,,,,,,,
avgalg,Fit a simple mean to a subset of the data and return predictions for (i) a (different) subset of the data and (ii) the original data.,Mean predictor constructed using mean() [base R]. Observation weights (weight_var) are not taken into account (i.e. no training stage). ,Vector of predictions (predicted value of Y) ['pred' 'pred_is'] and the fitted learner ['learner'].,,,,,,,,,,,,,,,
xgbalg,Fit a gradient boosted tree (classification regression) to a subset of the data and return predictions for (i) a (different) subset of the data and (ii) the original data.,Gradient boosted tree constructed using xgb.train() [xgboost]. Observation weights (weight_var) are handled internally (method: Observation with heigher weights are selected with higher probability in the bootstrap samples used to construct the individual learners) in the training stage (not taken into account at the prediction stage). ,Vector of predictions (predicted value of Y  OR  predicted probability of Y==1) ['pred' 'pred_is'] and the fitted learner ['learner'].,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,