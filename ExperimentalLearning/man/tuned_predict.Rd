% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tuned_predict.R
\name{tuned_predict}
\alias{tuned_predict}
\title{*Generate out of sample predictions based on in-sample cross-validation.}
\usage{
tuned_predict(df, LHS, RHS, algorithm,
  custom_param = ExpLearning.Default$custom_param,
  innerfold = ExpLearning.Default$innerfold,
  rand_grid_iter = ExpLearning.Default$rand_grid_iter,
  tuning_method = ExpLearning.Default$tuning_method,
  max_core = ExpLearning.Default$max_core,
  weight_var = ExpLearning.Default$weight_var,
  fold_var = ExpLearning.Default$weight_var,
  cluster_var = ExpLearning.Default$cluster_var,
  fold_method = ExpLearning.Default$fold_method,
  losstype = ExpLearning.Default$losstype, task = ExpLearning.Default$task,
  output_path = eval(parse(text = ExpLearning.Default$output_path)),
  quiet = ExpLearning.Default$quiet, execution_id = eval(parse(text =
  ExpLearning.Default$execution_id)))
}
\arguments{
\item{df}{*Datatable containing the data [data.table].}

\item{LHS}{*Name of the independent variable [character].}

\item{RHS}{*Names of all dependent variables (may incl. group_var, control_var and id_var) [character].}

\item{algorithm}{*Name of individual algorithm to be tuned [character].}

\item{custom_param}{*Custom tuning parameters supplied to the prediction function and used in place of the default values (if tuning_method==""no_tuning"") [list - misc].}

\item{innerfold}{*Number of CV folds used in inner CV routine [integer].}

\item{rand_grid_iter}{*Number of random grid search iterations (performed if tuning_method==""rand_grid"") [integer].}

\item{tuning_method}{*Tuning method [character].}

\item{max_core}{*The maximum number of cores to be used in all parallelised loops [integer].}

\item{cluster_var}{*Name of variable containing observation level cluster identifiers (integer) [character].}

\item{fold_method}{*Method used to generate CV folds (and the train-holdout split) [cluster_count (target cluster count), obs_count (target observation count), stratification (target stratification)].}

\item{losstype}{*Loss function used to tune the individiual learners and the ensemble neg_mse_brier, loglik, auc, accuracy, balanced_accuracy, r2].}

\item{task}{*The nature of the prediction task  [regression (regression), classification (classification)].}

\item{output_path}{*Directory within which all model output (e.g. tuning graphs) is stored [path].}

\item{quiet}{*Verbosity settings [0 (verbose), 1 (print only key stats and progress updates), 2 (silent) - 0.5 (test and development mode)].}

\item{execution_id}{*Unique ID generated at the beginning of each model construction process - all output is associated with this ID [character].}

\item{weight}{*Vector of observation weights [integer or numeric].}
}
\value{
*A list of out of sample predictions along with the optimal parameters selected.
}
\description{
*.
}

