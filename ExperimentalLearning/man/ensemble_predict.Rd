% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ensemble_predict.R
\name{ensemble_predict}
\alias{ensemble_predict}
\title{*Generate an in-sample fitted ensembled based on in-sample tuned out of sample predictions.}
\usage{
ensemble_predict(df, LHS, RHS, cluster_var = ExpLearning.Default$cluster_var,
  custom_param = ExpLearning.Default$custom_param,
  weight_var = ExpLearning.Default$weight_var,
  predictor = ExpLearning.Default$predictor,
  innerfold = ExpLearning.Default$innerfold,
  quiet = ExpLearning.Default$quiet,
  rand_grid_iter = ExpLearning.Default$rand_grid_iter,
  fold_var = ExpLearning.Default$fold_var, task = ExpLearning.Default$task,
  max_core = ExpLearning.Default$max_core,
  fold_method = ExpLearning.Default$fold_method,
  losstype = ExpLearning.Default$losstype, output_path = eval(parse(text =
  ExpLearning.Default$output_path)),
  tuning_method = ExpLearning.Default$tuning_method,
  ensemble_agg = ExpLearning.Default$ensemble_agg,
  tune_only = ExpLearning.Default$tune_only, execution_id = eval(parse(text
  = ExpLearning.Default$execution_id)))
}
\arguments{
\item{df}{*Datatable containing the data [data.table].}

\item{LHS}{*Name of the independent variable [character].}

\item{RHS}{*Names of all dependent variables (may incl. group_var, control_var and id_var) [character].}

\item{cluster_var}{*Name of variable containing observation level cluster identifiers (integer) [character].}

\item{custom_param}{*Custom tuning parameters supplied to the prediction function and used in place of the default values (if tuning_method==""no_tuning"") [list - misc].}

\item{predictor}{*List of algorithms included in ensemble learner [ols (linear regression), rf (random forest (classification OR regression)), avg (simple mean), elnet (elastic net), logit (logistic regression), tree (tree (classification or regression)), xgb (gradient boosted tree (classification or regression))] [character].}

\item{innerfold}{*Number of CV folds used in inner CV routine [integer].}

\item{quiet}{*Verbosity settings [0 (verbose), 1 (print only key stats and progress updates), 2 (silent) - 0.5 (test and development mode)].}

\item{rand_grid_iter}{*Number of random grid search iterations (performed if tuning_method==""rand_grid"") [integer].}

\item{fold_var}{*Name of variable containing observation level fold identifiers (integer) [character].}

\item{task}{*The nature of the prediction task  [regression (regression), classification (classification)].}

\item{max_core}{*The maximum number of cores to be used in all parallelised loops [integer].}

\item{fold_method}{*Method used to generate CV folds (and the train-holdout split) [cluster_count (target cluster count), obs_count (target observation count), stratification (target stratification)].}

\item{losstype}{*Loss function used to tune the individiual learners and the ensemble neg_mse_brier, loglik, auc, accuracy, balanced_accuracy, r2].}

\item{output_path}{*Directory within which all model output (e.g. tuning graphs) is stored [path].}

\item{tuning_method}{*Tuning method [character].}

\item{ensemble_agg}{*Method used to aggregate the individual learners into an ensemble learner [ols  (linear regression on individual learners predictions in the case of a regression task vs. logit regression on individual learner predictions in the case of a classification task), nnls (weights derived through non-negative least squares)]. [character].}

\item{tune_only}{*Whether to generate predictions (or to return only the tunes parameters or ensemble weights) [logical].}

\item{execution_id}{*Unique ID generated at the beginning of each model construction process - all output is associated with this ID [character].}

\item{weight}{*Vector of observation weights [integer or numeric].}
}
\value{
*A list of ensemble weights and tuning parameters selected for each of the individual learners.
}
\description{
*.
}

