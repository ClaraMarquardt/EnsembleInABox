% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/oos_predict.R
\name{oos_predict}
\alias{oos_predict}
\title{*Generate out of sample predictions based on a set of given ensemble weights and a list of individual leaners each of which is fit and tuned on the entire training data.}
\usage{
oos_predict(df, LHS, RHS, from, to, stack_model,
  custom_param = ExpLearning.Default$custom_param,
  cluster_var = ExpLearning.Default$cluster_var,
  tuning_method = ExpLearning.Default$tuning_method,
  weight_var = ExpLearning.Default$weight_var,
  fold_method = ExpLearning.Default$fold_method,
  task = ExpLearning.Default$task, losstype = ExpLearning.Default$losstype,
  max_core = ExpLearning.Default$max_core,
  ensemble_agg = ExpLearning.Default$ensemble_agg,
  output_path = eval(parse(text = ExpLearning.Default$output_path)),
  rand_grid_iter = ExpLearning.Default$rand_grid_iter,
  predictor = ExpLearning.Default$predictor,
  innerfold = ExpLearning.Default$innerfold,
  tune_only = ExpLearning.Default$tune_only,
  quiet = ExpLearning.Default$quiet, execution_id = eval(parse(text =
  ExpLearning.Default$execution_id)))
}
\arguments{
\item{df}{*Datatable containing the data [data.table].}

\item{LHS}{*Name of the independent variable [character].}

\item{RHS}{*Names of all dependent variables (may incl. group_var, control_var and id_var) [character].}

\item{from}{*Observations on which to train an algorithm [integer].}

\item{to}{*Observations on which to predict [integer].}

\item{stack_model}{*List of meta-learners or ensemble weights, i.e. learners used to stack the individual learners and generate ensemble predictions [list - misc].}

\item{custom_param}{*Custom tuning parameters supplied to the prediction function and used in place of the default values (if tuning_method==""no_tuning"") [list - misc].}

\item{cluster_var}{*Name of variable containing observation level cluster identifiers (integer) [character].}

\item{tuning_method}{*Tuning method [character].}

\item{fold_method}{*Method used to generate CV folds (and the train-holdout split) [cluster_count (target cluster count), obs_count (target observation count), stratification (target stratification)].}

\item{task}{*The nature of the prediction task  [regression (regression), classification (classification)].}

\item{losstype}{*Loss function used to tune the individiual learners and the ensemble neg_mse_brier, loglik, auc, accuracy, balanced_accuracy, r2].}

\item{max_core}{*The maximum number of cores to be used in all parallelised loops [integer].}

\item{ensemble_agg}{*Method used to aggregate the individual learners into an ensemble learner [ols  (linear regression on individual learners predictions in the case of a regression task vs. logit regression on individual learner predictions in the case of a classification task), nnls (weights derived through non-negative least squares)]. [character].}

\item{output_path}{*Directory within which all model output (e.g. tuning graphs) is stored [path].}

\item{rand_grid_iter}{*Number of random grid search iterations (performed if tuning_method==""rand_grid"") [integer].}

\item{predictor}{*List of algorithms included in ensemble learner [ols (linear regression), rf (random forest (classification OR regression)), avg (simple mean), elnet (elastic net), logit (logistic regression), tree (tree (classification or regression)), xgb (gradient boosted tree (classification or regression))] [character].}

\item{innerfold}{*Number of CV folds used in inner CV routine [integer].}

\item{tune_only}{*Whether to generate predictions (or to return only the tunes parameters or ensemble weights) [logical].}

\item{quiet}{*Verbosity settings [0 (verbose), 1 (print only key stats and progress updates), 2 (silent) - 0.5 (test and development mode)].}

\item{weight}{*Vector of observation weights [integer or numeric].}
}
\value{
*A list of out of sample predictions generated by (a) the ensemble  and (b) the individual learners along with
}
\description{
*.
}

