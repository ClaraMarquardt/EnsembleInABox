#----------------------------------------------------------------------------#

#' @title *Generate out of sample predictions based on a set of given ensemble weights and a list of individual leaners each of which is fit and tuned on the entire training data.
#'
#' @description *.
#'
#' @export
#' @imoprt data.table
#' @param df *Datatable containing the data [data.table].
#' @param LHS *Name of the independent variable [character].
#' @param RHS *Names of all dependent variables (may incl. group_var, control_var and id_var) [character].
#' @param cluster_var *Name of variable containing observation level cluster identifiers (integer) [character].
#' @param from *Observations on which to train an algorithm [integer].
#' @param to *Observations on which to predict [integer].
#' @param weight *Vector of observation weights [integer or numeric].
#' @param fold_method *Method used to generate CV folds (and the train-holdout split) [cluster_count (target cluster count), obs_count (target observation count), stratification (target stratification)].
#' @param task *The nature of the prediction task  [regression (regression), classification (classification)].
#' @param losstype *Loss function used to tune the individiual learners and the ensemble neg_mse_brier, loglik, auc, accuracy, balanced_accuracy, r2].
#' @param output_path *Directory within which all model output (e.g. tuning graphs) is stored [path].
#' @param custom_param *Custom tuning parameters supplied to the prediction function and used in place of the default values (if tuning_method==""no_tuning"") [list - misc]. 
#' @param rand_grid_iter *Number of random grid search iterations (performed if tuning_method==""rand_grid"") [integer]. 
#' @param predictor *List of algorithms included in ensemble learner [ols (linear regression), rf (random forest (classification OR regression)), avg (simple mean), elnet (elastic net), logit (logistic regression), tree (tree (classification or regression)), xgb (gradient boosted tree (classification or regression))] [character].
#' @param tuning_method *Tuning method [character].
#' @param innerfold *Number of CV folds used in inner CV routine [integer].
#' @param max_core *The maximum number of cores to be used in all parallelised loops [integer].
#' @param stack_model *List of meta-learners or ensemble weights, i.e. learners used to stack the individual learners and generate ensemble predictions [list - misc].
#' @param ensemble_agg *Method used to aggregate the individual learners into an ensemble learner [ols  (linear regression on individual learners predictions in the case of a regression task vs. logit regression on individual learner predictions in the case of a classification task), nnls (weights derived through non-negative least squares)]. [character].
#' @param tune_only *Whether to generate predictions (or to return only the tunes parameters or ensemble weights) [logical].
#' @param quiet *Verbosity settings [0 (verbose), 1 (print only key stats and progress updates), 2 (silent) - 0.5 (test and development mode)].
#' @return *A list of out of sample predictions generated by (a) the ensemble  and (b) the individual learners along with
#' @examples

oos_predict <- function(df,LHS,RHS, from,to, stack_model, 
                 custom_param=ExpLearning.Default$custom_param,
                 cluster_var=ExpLearning.Default$cluster_var,
                 tuning_method=ExpLearning.Default$tuning_method,  
                 weight_var=ExpLearning.Default$weight_var, 
                 fold_method=ExpLearning.Default$fold_method,
                 task=ExpLearning.Default$task,
                 losstype=ExpLearning.Default$losstype,
                 max_core=ExpLearning.Default$max_core,
                 ensemble_agg=ExpLearning.Default$ensemble_agg,
                 output_path=eval(parse(text=ExpLearning.Default$output_path)), 
                 rand_grid_iter=ExpLearning.Default$rand_grid_iter,
                 predictor=ExpLearning.Default$predictor,
                 innerfold=ExpLearning.Default$innerfold,
                 tune_only=ExpLearning.Default$tune_only,
                 quiet=ExpLearning.Default$quiet,
                 execution_id=eval(parse(text=ExpLearning.Default$execution_id))) {
  

  # matrix with one row per obs and one column per algorithm
  phat <- matrix(rep(NA, nrow(df[to,]) * length(predictor)), ncol = length(predictor))
  
  param_list   <- list()
  learner_list <- list()

  # predictions (individual learners) from fitting to the entire data  
  for(a in 1:length(predictor)) {

    tuned <- tuning(df=df,LHS=LHS,RHS=RHS,cluster_var=cluster_var,fold_method=fold_method,
                    task=task, losstype=losstype, output_path=output_path, rand_grid_iter=rand_grid_iter, 
                    fold_in=from,fold_out=to,custom_param=custom_param, weight_var=weight_var, 
                    max_core=max_core, tuning_method = tuning_method, algorithm=predictor[[a]],
                    innerfold=innerfold, quiet=quiet, execution_id=execution_id, 
                    fold_out_id="oos", tune_only=tune_only)

    if (tune_only==FALSE) {
      phat[,a] <- tuned$pred
    }

    param_list[[predictor[[a]]]]   <- tuned$param
    learner_list[[predictor[[a]]]] <- tuned$learner

    if (quiet==0.5 & tune_only==FALSE) {
      print(paste0("OOS loss - ", predictor[[a]], ":"))
      print(tuned$pred_loss)
      print(tuned$pred_loss_auc)
    }

  }

  if (tune_only==FALSE) {
  
    # learner list
    names(learner_list) <- predictor
  
    # individual prediction list
    ind_pred <- lapply(data.table(phat),function(x) x)
    names(ind_pred) <- predictor
  
    # predict linearly according to ensemble
    phat_mod           <- matrix(c(phat), ncol=ncol(phat))
    phat_mod           <- data.frame(phat_mod)
    names(phat_mod)    <- c(predictor)

    if (ensemble_agg=="ols" & length(learner_list) >1 ) {
        phat_ensemble   <- predict(stack_model$model, newdata=phat_mod, type="response")
    } else {
        phat_ensemble   <- as.vector(as.vector(stack_model$model)%*%t(as.matrix(phat_mod)))
    }
  
    if (quiet==0.5) {
      print(paste0("OOS loss - Ensemble:"))

      print(loss(phat_ensemble, df[to,get(LHS)], losstype="auc",
        weight=df[to,get(weight_var)], task=task))
      print(loss(phat_ensemble, df[to,get(LHS)], losstype="neg_mse_brier",
        weight=df[to,get(weight_var)], task=task))
    }
  
    if (ensemble_agg=="ols" & length(learner_list) >1) {
      phat_ensemble_nnls <- as.vector(as.vector(stack_model$nnls)%*%t(phat_mod))
    } else {
      phat_ensemble_nnls <- phat_ensemble
    }
  
    # create model predict function
    function_arg        <- alist(learner_list_arg = learner_list, 
                              RHS_arg=RHS, LHS_arg=LHS, df=NULL, quiet=TRUE, task_arg=task,
                              stack_model_arg=stack_model$model, learner=predictor)
    function_body       <- body(model_predict_function_template)
  
    model_predict_function <- make_function(arg=function_arg, 
      body=function_body)
  
    return(c(list(ensemble_pred=phat_ensemble, ensemble_pred_nnls=phat_ensemble_nnls),
        ind_pred=ind_pred, param=param_list, model_predict=model_predict_function, 
        learner_list=learner_list))
  
  } else {
     return(c(param=param_list))
  }

}

#----------------------------------------------------------------------------#


